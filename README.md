# Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer

ğŸ“¢ **Accepted at ICCV 2025** â€¢ ğŸŒ [![Project Page](https://img.shields.io/badge/Project-Website-blue)](https://ashiq24.github.io/local-scale-equivariance/)

[Md Ashiqur RahmanÂ¹](mailto:rahman79@purdue.edu), [Chiao-An YangÂ¹](mailto:yang2892@purdue.edu), [Michael N. ChengÂ¹](mailto:cheng610@purdue.edu), [Lim Jun HaoÂ²](mailto:ljunhao@dso.org.sg), [Jeremiah JiangÂ²](mailto:jjiang@dso.org.sg), [Teck-Yian LimÂ²](mailto:tylim@dso.org.sg), [Raymond A. YehÂ¹](mailto:raymond.yeh@purdue.edu)

Â¹Purdue University, Â²DSO National Laboratories

## Abstract

In computer vision, scale variation is a persistent challenge where objects of the same class can appear at different sizes due to intrinsic differences and extrinsic factors like camera distance. While prior work addresses global scale invariance, real-world images often experience **local scale changes** where only parts of the image are resized. Existing neural networks, including state-of-the-art vision transformers, are not inherently robust to such transformations.

We propose **Deep Equilibrium Canonicalizer (DEC)**, a novel method that achieves local scale equivariance through:
- **Monotone Scaling Group**: A mathematically tractable approximation to local scaling
- **Deep Equilibrium Models (DEQs)**: Efficient canonicalization via fixed-point computation
- **Latent Canonicalization**: Applied to feature space as well as the input images  

Our method consistently improves both accuracy and scale consistency metrics across various architectures (ViT, Swin, BEiT, DINOv2, ResNet, DeiT) on synthetic and real-world datasets.

## ğŸ”¥ Key Contributions

1. **First group-theoretic approach** to local scale equivariance with monotone scaling groups
2. **Novel use of Deep Equilibrium Models** for efficient, differentiable canonicalization  
3. **Latent canonicalization** that integrates with any pretrained architecture
4. **Extensive validation** across 6 architectures on MNIST, and ImageNet

## ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Datasets](#datasets)
- [Quick Start](#quick-start)
- [Experiments](#experiments)
  - [MNIST Experiments](#mnist-experiments)
  - [ImageNet Experiments](#imagenet-experiments)
- [Repository Structure](#repository-structure)
- [Troubleshooting](#troubleshooting)
- [Citation](#citation)
- [License](#license)

## ğŸš€ Installation

### Option 1: Conda Environment (Recommended)

```bash
# Clone the repository
git clone https://github.com/your-username/local-scale-equivariance.git
cd local-scale-equivariance

# Create and activate the main environment
conda env create -f environment.yml
conda activate local_scale

# For data generation pipeline (optional)
cd datagen_ImNet
conda env create -f environment.yml
conda activate inpaint
```


### Dependencies

**Core Requirements:**
- Python 3.11+
- PyTorch 2.1.2+ with CUDA 12.1+
- timm 1.0.14
- torchdeq 0.1.0
- transformers 4.44.2+

**Full dependency list:** See `environment.yml`

## ğŸ“Š Datasets

### MNIST Multi-Scale
- **Auto-downloaded**: Automatically handled by the training scripts
- **Description**: Multi-digit MNIST with local scaling transformations

### ImageNet
- **Required**: Standard ImageNet-1K dataset
- **Multi-Scale ImageNet**: Generated using our data generation pipeline

### Custom Multi-Scale Dataset Generation
```bash
# Activate data generation environment
conda activate inpaint
cd datagen_ImNet

# Generate multi-scale datasets (see datagen_ImNet/README.md for details)
python inpaint_imagenet.py --help
```

##  ğŸ§ª Experiments

### MNIST Example 

```bash
# Single experiment with Swin Transformer + DEC
bash run_mnist.sh config_1.yaml swin_data_augmentation 42
bash run_mnist.sh config_1.yaml ada_swin_dem 42
```

### ImageNet Example

```bash
# baselines
bash imagenet_baselines.sh swin base_swin 20

# DEC method experiment  
bash imagenet_dem.sh swin dem_swin 20
```

### Batch ImageNet Experiments

**Run All Baselines:**
```bash
# Runs all baseline variants for all models (swin, vit, deit, beit)
bash imnet_all_baselines.sh
```

**Run All DEC Experiments:**
```bash
# Runs DEC experiments for all models
bash imnet_all_dem.sh
```

These scripts automatically run experiments with multiple model-configuration pairs.

### MNIST Experiments

#### Single Experiment
```bash
bash run_mnist.sh <config_file> <config_name> <random_seed>

# Examples:
bash run_mnist.sh config_1.yaml swin_data_augmentation 70
bash run_mnist.sh config_1.yaml ada_vit_dem_1 71
```

#### Batch Experiments (All Models)
```bash
# Run all data augmentation baselines
CONFIGS_TO_RUN=$data_aug_configs bash run_all_mnist.sh

# Run all DEC experiments  
CONFIGS_TO_RUN=$ada_dem_configs bash run_all_mnist.sh

# Run all canonicalization baselines
CONFIGS_TO_RUN=$canon_configs bash run_all_mnist.sh
```

## ğŸ“ Repository Structure

```
local-scale-equivariance/
â”œâ”€â”€ ğŸ“ config/                    # MNIST experiment configurations
â”‚   â””â”€â”€ config_1.yaml
â”œâ”€â”€ ğŸ“ imagenet/                  # ImageNet-specific code
â”‚   â”œâ”€â”€ config/adapter_config.yaml
â”‚   â””â”€â”€ timm_*.py                 # Model implementations
â”œâ”€â”€ ğŸ“ models/                    # Core model implementations
â”‚   â”œâ”€â”€ canonicalizer_wrapper.py # Canonicalization baseline
â”‚   â”œâ”€â”€ surrogate_model.py        # DEC implementation
â”‚   â””â”€â”€ ada_*.py                  # Adaptive model wrappers
â”œâ”€â”€ ğŸ“ layers/                    # Core DEC layers
â”‚   â””â”€â”€ adapter.py                # Deep Equilibrium adaptation
â”œâ”€â”€ ğŸ“ train/                     # Training infrastructure  
â”‚   â””â”€â”€ trainer.py                # Bi-level optimization
â”œâ”€â”€ ğŸ“ evaluation/                # Metrics and evaluation
â”œâ”€â”€ ğŸ“ utils/                     # Utility functions
â”œâ”€â”€ ğŸ“ dataloader/                # Data loading utilities
â”œâ”€â”€ ğŸ“ datagen_ImNet/             # Data generation pipeline
â”‚   â”œâ”€â”€ environment.yml           # Separate environment
â”‚   â””â”€â”€ README.md                 # Data generation docs
â”œâ”€â”€ ğŸ“„ train_mnist.py             # MNIST training script
â”œâ”€â”€ ğŸ“„ train_imagenet.py          # ImageNet training script
â”œâ”€â”€ ğŸ“„ imagenet_baselines.sh      # Baseline experiments
â”œâ”€â”€ ğŸ“„ imagenet_dem.sh            # DEC experiments  
â”œâ”€â”€ ğŸ“„ imnet_all_baselines.sh     # Batch baseline experiments
â”œâ”€â”€ ğŸ“„ imnet_all_dem.sh           # Batch DEC experiments
â”œâ”€â”€ ğŸ“„ run_mnist.sh               # Single MNIST experiment
â”œâ”€â”€ ğŸ“„ run_all_mnist.sh           # Batch MNIST experiments
â”œâ”€â”€ ğŸ“„ YParams.py                 # YAML parameter utilities
â””â”€â”€ ğŸ“„ TUTORIAL.ipynb             # Tutorial notebook
```


### Logging and Monitoring

- **WandB Integration**: Automatic logging enabled
- **Checkpoints**: Saved in `./weights/` directory  
- **Logs**: Console output shows training progress


## ğŸ¤ Contributing

We welcome contributions! Please:

1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality  
4. Submit a pull request

## ğŸ“„ Citation

If you find this work useful, please cite:

```bibtex
@inproceedings{rahman2025local,
  title={Local Scale Equivariance with Latent Deep Equilibrium Canonicalizer},
  author={Md Ashiqur Rahman and Chiao-An Yang and Michael N. Cheng and Jun Hao Lim and Jeremiah Jiang and Teck-Yian Lim and Raymond A. Yeh},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2025}
}
```


## ğŸ™ Acknowledgments

- PyTorch Image Models ([timm](https://github.com/rwightman/pytorch-image-models)) for model implementations
- Deep Equilibrium Models ([torchdeq](https://github.com/locuslab/torchdeq)) for DEQ implementations  
- HuggingFace Transformers for transformer utilities
- The computer vision community for inspiring this work

---
For questions, please contact [rahman79@purdue.edu](mailto:rahman79@purdue.edu)
